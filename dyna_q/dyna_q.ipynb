{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dyna-Q**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env():\n",
    "    def __init__(self, verbose: bool = False) -> None:\n",
    "        self.verbose = verbose\n",
    "        self.coordinates = {\n",
    "            'A': ((6, 1),),\n",
    "            'W': ((3, range(3)), (range(5, 8), 3)),\n",
    "            'T': ((range(3), 8), (3, range(8, 12))),\n",
    "            'P': ((6, 10), (0, 11)),\n",
    "            'LP': ((1, 2),),\n",
    "            'G': ((1, 10),)\n",
    "        }\n",
    "        self.generate_grid()\n",
    "        self.generate_reward_map()\n",
    "\n",
    "    def generate_grid(self):\n",
    "        grid = np.zeros((8, 12), dtype=np.object0)\n",
    "        for key in list(self.coordinates.keys()):\n",
    "            for values in self.coordinates[key]:\n",
    "                grid[values] = key\n",
    "        self.grid = pd.DataFrame(grid)\n",
    "        if self.verbose:\n",
    "            display(self.grid)\n",
    "\n",
    "    def generate_reward_map(self):\n",
    "        reward_map = np.zeros((8, 12), dtype=np.float32)\n",
    "        reward_map[self.coordinates['G'][0]] = 1\n",
    "        self.reward_map = pd.DataFrame(reward_map)\n",
    "        if self.verbose:\n",
    "            display(self.reward_map)\n",
    "\n",
    "    def get_reward(self, coordinates: tuple = None):\n",
    "        return self.reward_map.loc[coordinates]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Env()\n",
    "env.get_reward((0, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>G</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W</td>\n",
       "      <td>W</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0  1   2  3  4  5  6  7  8  9  10 11\n",
       "0  0  0   0  0  0  0  0  0  T  0  0  P\n",
       "1  0  0  LP  0  0  0  0  0  T  0  G  0\n",
       "2  0  0   0  0  0  0  0  0  T  0  0  0\n",
       "3  W  W   W  0  0  0  0  0  T  T  T  T\n",
       "4  0  0   0  0  0  0  0  0  0  0  0  0\n",
       "5  0  0   0  W  0  0  0  0  0  0  0  0\n",
       "6  0  A   0  W  0  0  0  0  0  0  P  0\n",
       "7  0  0   0  W  0  0  0  0  0  0  0  0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self,\n",
    "                 gamma: float = 1.0,  # undiscounted task\n",
    "                 step_size: float = 0.1,\n",
    "                 epsilon: float = 0.1,\n",
    "                 planning_steps: int = 100\n",
    "                 ) -> None:\n",
    "        self.env = Env()\n",
    "        self.gamma = gamma\n",
    "        self.step_size = step_size\n",
    "        self.epsilon = epsilon\n",
    "        self.planning_steps = planning_steps\n",
    "        self.n_actions = 4\n",
    "        self.actions = list(range(self.n_actions))\n",
    "        self.last_action = -1\n",
    "        self.last_state = -1\n",
    "        self.n_states = self.env.grid.size\n",
    "        self.start_position = self.coord_to_state(\n",
    "            list(reversed(self.env.coordinates.get('A')[0])))\n",
    "        self.position = self.start_position\n",
    "        self.q_values = self.init_q_values()\n",
    "        self.model = {}  # model[state][action] = (new state, reward)\n",
    "        self.random_generator = np.random.RandomState(seed=17)\n",
    "        self.done = False\n",
    "\n",
    "    def coord_to_state(self, coordinates: tuple) -> int:\n",
    "        return coordinates[0]*10 + coordinates[1]\n",
    "\n",
    "    def state_to_coord(self, state: int):\n",
    "        return (int(state//10), state % 10)\n",
    "\n",
    "    def init_q_values(self) -> None:\n",
    "        q_values = {}\n",
    "        rows, cols = self.env.grid.index, self.env.grid.columns\n",
    "        for col in cols:\n",
    "            for row in rows:\n",
    "                q_values[self.coord_to_state((col, row))] = np.zeros(\n",
    "                    4, dtype=np.float32)\n",
    "        return q_values\n",
    "\n",
    "    def update_model(self, last_state: int, last_action: int, state: int, reward: int) -> None:\n",
    "        \"\"\"\n",
    "        Adds a new transition to the model, if the state is encountered for \n",
    "        the first time, creates a new key\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.model[last_state][last_action] = (state, reward)\n",
    "        except KeyError:\n",
    "            self.model[last_state] = {}\n",
    "            self.model[last_state][last_action] = (state, reward)\n",
    "\n",
    "    def update_coord(self, coord: tuple, action: int) -> tuple:\n",
    "        \"\"\"\n",
    "        Given a state and an action, moves the agent on the grid\n",
    "        If the agent encounters a wall or the edge of the grid, the initial position is returned\n",
    "        If the agent falls into a whole ('T') or finds the goal ('G'), the episode ends\n",
    "        \"\"\"\n",
    "        assert action in [0, 1, 2, 3], f\"Invalid action {action}\"\n",
    "        x, y = coord\n",
    "        if action == 0:\n",
    "            y -= 1\n",
    "        elif action == 1:\n",
    "            x += 1\n",
    "        elif action == 2:\n",
    "            y += 1\n",
    "        elif action == 3:\n",
    "            x -= 1\n",
    "\n",
    "        # if the action moves the agent out of bounds\n",
    "        if x not in range(0, self.env.grid.shape[1]):\n",
    "            return coord\n",
    "        if y not in range(0, self.env.grid.shape[0]):\n",
    "            return coord\n",
    "\n",
    "        # /!\\ when parsing the dataframe x and y are reversed\n",
    "        # if the agent bumps into a wall\n",
    "        if self.env.grid.loc[y, x] == 'W':\n",
    "            print('W')\n",
    "            return coord\n",
    "        # if the agent goes through the portal\n",
    "        if self.env.grid.loc[y, x] == 'P':\n",
    "            return (11, 0)\n",
    "        # if the agent encounters a terminal state (whole or goal)\n",
    "        if self.env.grid.loc[y, x] in ['T', 'G']:\n",
    "            self.done = True\n",
    "\n",
    "        self.position == (x, y)\n",
    "        return (x, y)\n",
    "\n",
    "    def update_state(self, state, action):\n",
    "        assert action in [0, 1, 2, 3], f\"Invalid action {action}\"\n",
    "        coord = self.state_to_coord(state)\n",
    "        updated_coord = self.update_coord(coord, action)\n",
    "        updated_state = self.coord_to_state(updated_coord)\n",
    "        self.position = updated_state\n",
    "        return updated_state\n",
    "\n",
    "    def argmax(self, q_values) -> int:\n",
    "        \"\"\"\n",
    "        Selects the index of the highest action value\n",
    "        Breaks ties randomly\n",
    "        \"\"\"\n",
    "        return self.random_generator.choice(np.flatnonzero(q_values == np.max(q_values)))\n",
    "\n",
    "    def epsilon_greedy(self, state) -> int:\n",
    "        \"\"\"\n",
    "        Returns an action using an epsilon-greedy policy \n",
    "        w.r.t. the current action-value function\n",
    "        \"\"\"\n",
    "        # convert the state to coordinates to query the q_values\n",
    "        if self.random_generator.rand() < self.epsilon:\n",
    "            action = self.random_generator.choice(self.actions)\n",
    "        else:\n",
    "            values = self.q_values[state]\n",
    "            action = self.argmax(values)\n",
    "        return action\n",
    "\n",
    "    def planning_step(self):\n",
    "        \"\"\"\n",
    "        Performs planning (indirect RL)\n",
    "        \"\"\"\n",
    "        for _ in range(self.planning_steps):\n",
    "            # select a visited state\n",
    "            planning_state = self.random_generator.choice(\n",
    "                list(self.model.keys()))\n",
    "            # select a recorded action\n",
    "            planning_action = self.random_generator.choice(\n",
    "                list(self.model[planning_state].keys()))\n",
    "            # get the predicted next state and reward\n",
    "            next_state, reward = self.model[planning_state][planning_action]\n",
    "            # update the values in case of terminal state\n",
    "            if next_state == -1:\n",
    "                update = self.q_values[planning_state][planning_action]\n",
    "                update += self.step_size * (reward - update)\n",
    "                self.q_values[planning_state][planning_action] = update\n",
    "            # update the values in case of non-terminal state\n",
    "            else:\n",
    "                update = self.q_values[planning_state][planning_action]\n",
    "                update += self.step_size * \\\n",
    "                    (reward + self.gamma *\n",
    "                     np.max(self.q_values[next_state]) - update)\n",
    "                self.q_values[planning_state][planning_action] = update\n",
    "\n",
    "    def agent_start(self, state: int):\n",
    "        \"\"\"\n",
    "        Called at the start of an episode, takes the first action \n",
    "        given the initial state\n",
    "        \"\"\"\n",
    "        self.past_state = state\n",
    "        self.past_action = self.epsilon_greedy(state)\n",
    "        # take the action\n",
    "        self.update_state(state, self.past_action)\n",
    "        return self.past_action\n",
    "\n",
    "    def step(self, state: int, reward: int):\n",
    "        # direct RL update\n",
    "        update = self.q_values[self.past_state][self.past_action]\n",
    "        update += self.step_size * \\\n",
    "            (reward + self.gamma * np.max(self.q_values[state]) - update)\n",
    "        self.q_values[self.past_state][self.past_action] = update\n",
    "        # model update\n",
    "        self.update_model(self.past_state, self.past_action, state, reward)\n",
    "        # planning step\n",
    "        self.planning_step()\n",
    "        # action selection using the e-greedy policy\n",
    "        action = self.epsilon_greedy(state)\n",
    "        self.update_state(state, action)\n",
    "        # before performing the action, save the current state and action\n",
    "        self.past_state = state\n",
    "        self.past_action = action\n",
    "\n",
    "        return self.past_action\n",
    "\n",
    "    def agent_end(self):\n",
    "        \"\"\"\n",
    "        Called once the agent reaches a terminal state \n",
    "        \"\"\"\n",
    "        terminal_coordinates = self.state_to_coord(self.position)\n",
    "        # the coordinates must be reversed when querying the dataframe\n",
    "        reward = self.env.get_reward(terminal_coordinates[::-1])\n",
    "        # direct RL update for a terminal state\n",
    "        update = self.q_values[self.past_state][self.past_action]\n",
    "        update += self.step_size * (reward - update)\n",
    "        self.q_values[self.past_state, self.past_action] = update\n",
    "        # model update with next_action = -1\n",
    "        self.update_model(self.past_state, self.past_action, -1, reward)\n",
    "        # planning step\n",
    "        self.planning_step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos: 6\n",
      "action: 1\n",
      "pos: 16\n",
      "action: 0\n",
      "pos: 15\n",
      "action: 2\n",
      "pos: 16\n"
     ]
    }
   ],
   "source": [
    "a = Agent(planning_steps=4)\n",
    "a.agent_start(a.start_position)\n",
    "print(f'pos: {a.position}')\n",
    "for _ in range(3):\n",
    "    action = a.step(a.position, a.env.get_reward(a.state_to_coord(a.position)))\n",
    "    print(f'action: {action}')\n",
    "    print(f'pos: {a.position}')\n",
    "a.update_state(111, 3)\n",
    "a.agent_end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{16: {3: (6, 0.0), 0: (15, 0.0)}, 6: {1: (16, 0.0)}, 15: {2: (-1, 1.0)}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.19, 0.  ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.q_values.get(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Agent()\n",
    "assert a.position == 16\n",
    "a.position\n",
    "a.update_state(105, 2)\n",
    "a.position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>G</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W</td>\n",
       "      <td>W</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0  1   2  3  4  5  6  7  8  9  10 11\n",
       "0  0  0   0  0  0  0  0  0  T  0  0  P\n",
       "1  0  0  LP  0  0  0  0  0  T  0  G  0\n",
       "2  0  0   0  0  0  0  0  0  T  0  0  0\n",
       "3  W  W   W  0  0  0  0  0  T  T  T  T\n",
       "4  0  0   0  0  0  0  0  0  0  0  0  0\n",
       "5  0  0   0  W  0  0  0  0  0  0  0  0\n",
       "6  0  A   0  W  0  0  0  0  0  0  P  0\n",
       "7  0  0   0  W  0  0  0  0  0  0  0  0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
